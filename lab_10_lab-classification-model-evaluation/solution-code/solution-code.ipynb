{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 2: Predicting Chronic Kidney Disease in Patients\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus on steps exploring data, building models and evaluating the models we build.\n",
    "\n",
    "There are three links you may find important:\n",
    "- [A set of chronic kidney disease (CKD) data and other biological factors](./chronic_kidney_disease_full.csv).\n",
    "- [The CKD data dictionary](./chronic_kidney_disease_header.txt).\n",
    "- [An article comparing the use of k-nearest neighbors and support vector machines on predicting CKD](./chronic_kidney_disease.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define the problem.\n",
    "\n",
    "Suppose you're working for Mayo Clinic, widely recognized to be the top hospital in the United States. In your work, you've overheard nurses and doctors discuss test results, then arrive at a conclusion as to whether or not someone has developed a particular disease or condition. For example, you might overhear something like:\n",
    "\n",
    "> **Nurse**: Male 57 year-old patient presents with severe chest pain. FDP _(short for fibrin degradation product)_ was elevated at 13. We did an echo _(echocardiogram)_ and it was inconclusive.\n",
    "\n",
    "> **Doctor**: What was his interarm BP? _(blood pressure)_\n",
    "\n",
    "> **Nurse**: Systolic was 140 on the right; 110 on the left.\n",
    "\n",
    "> **Doctor**: Dammit, it's an aortic dissection! Get to the OR _(operating room)_ now!\n",
    "\n",
    "> _(intense music playing)_\n",
    "\n",
    "In this fictitious but [Shonda Rhimes-esque](https://en.wikipedia.org/wiki/Shonda_Rhimes#Grey's_Anatomy,_Private_Practice,_Scandal_and_other_projects_with_ABC) scenario, you might imagine the doctor going through a series of steps like a [flowchart](https://en.wikipedia.org/wiki/Flowchart), or a series of if-this-then-that steps to diagnose a patient. The first steps made the doctor ask what the interarm blood pressure was. Because interarm blood pressure took on the values it took on, the doctor diagnosed the patient with an aortic dissection.\n",
    "\n",
    "Your goal, as a research biostatistical data scientist at the nation's top hospital, is to develop a medical test that can improve upon our current diagnosis system for [chronic kidney disease (CKD)](https://www.mayoclinic.org/diseases-conditions/chronic-kidney-disease/symptoms-causes/syc-20354521).\n",
    "\n",
    "**Real-world problem**: Develop a medical diagnosis test that is better than our current diagnosis system for CKD.\n",
    "\n",
    "**Data science problem**: Develop a medical diagnosis test that reduces both the number of false positives and the number of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### 1. Read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd = pd.read_csv(\"../chronic_kidney_disease_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "     bgr  ...   pcv    wbcc  rbcc  htn   dm  cad  appet   pe  ane class  \n",
       "0  121.0  ...  44.0  7800.0   5.2  yes  yes   no   good   no   no   ckd  \n",
       "1    NaN  ...  38.0  6000.0   NaN   no   no   no   good   no   no   ckd  \n",
       "2  423.0  ...  31.0  7500.0   NaN   no  yes   no   poor   no  yes   ckd  \n",
       "3  117.0  ...  32.0  6700.0   3.9  yes   no   no   poor  yes  yes   ckd  \n",
       "4  106.0  ...  35.0  7300.0   4.6   no   no   no   good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check out the data dictionary. What are a few features or relationships you might be interested in checking out?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "- First, I want to check the `ckd` variable to see if unbalanced classes would be an issue here. (A 38/62 split probably won't be problematic.)\n",
    "- Secondly, since we want to predict `ckd`, I would probably want to compare each variable with `ckd` to see which variables appear to have predictive value.\n",
    "- Next, I'll want to check the patterns of missingness. Are any variables missing extensively so that it will be problematic? Is there any missingness that is explained by the data dictionary? (i.e. tests not run due to certain thresholds being met?)\n",
    "- Check out the distributions of each variable. Are there certain variables that overwhelmingly take on one value and thus might not be predictive?\n",
    "- Lots of these variables have \"blood\" in the name. If I'm trying to do a linear model (i.e. logistic regression, linear regression), there might be some relationship among these features. (I'm not a doctor, so I'll err on the side of caution here!) If certain features are correlated, then I'll want to include interaction terms or I'll want to remove one of them when building a linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 3. How much of the data is missing from each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        9\n",
       "bp        12\n",
       "sg        47\n",
       "al        46\n",
       "su        49\n",
       "rbc      152\n",
       "pc        65\n",
       "pcc        4\n",
       "ba         4\n",
       "bgr       44\n",
       "bu        19\n",
       "sc        17\n",
       "sod       87\n",
       "pot       88\n",
       "hemo      52\n",
       "pcv       71\n",
       "wbcc     106\n",
       "rbcc     131\n",
       "htn        2\n",
       "dm         2\n",
       "cad        2\n",
       "appet      1\n",
       "pe         1\n",
       "ane        1\n",
       "class      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age       2.25\n",
       "bp        3.00\n",
       "sg       11.75\n",
       "al       11.50\n",
       "su       12.25\n",
       "rbc      38.00\n",
       "pc       16.25\n",
       "pcc       1.00\n",
       "ba        1.00\n",
       "bgr      11.00\n",
       "bu        4.75\n",
       "sc        4.25\n",
       "sod      21.75\n",
       "pot      22.00\n",
       "hemo     13.00\n",
       "pcv      17.75\n",
       "wbcc     26.50\n",
       "rbcc     32.75\n",
       "htn       0.50\n",
       "dm        0.50\n",
       "cad       0.50\n",
       "appet     0.25\n",
       "pe        0.25\n",
       "ane       0.25\n",
       "class     0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * ckd.isnull().sum() / ckd.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Some of the data is missing from every column except for `class`. In particular, `rbc`, `wbcc`, and `rbcc` are missing over 100 observations each. I'm particularly concerned about the categories that are missing over 15% of their data. This is problematic and should be addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Suppose that I dropped every row that contained at least one missing value. (In the context of analysis with missing data, we call this a \"complete case analysis,\" because we keep only the complete cases!) How many rows would remain in our dataframe? What are at least two downsides to doing this?\n",
    "\n",
    "> There's a good visual on slide 15 of [this deck](https://liberalarts.utexas.edu/prc/_files/cs/Missing-Data.pdf) that shows what a complete case analysis looks like if you're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 25)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.dropna(axis = 0, how = 'any', inplace = False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "notckd    115\n",
       "ckd        43\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.dropna(axis = 0, how = 'any', inplace = False)['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** We'd drop 242 of our 400 observations (over 60% of our data!) by dropping each row that contains any missing value. \n",
    "\n",
    "Some downsides to this:\n",
    "- Of these 242 rows, many of them do have information filled in for some of the cells. If we drop any observation that contains at least one missing value, then I'm discarding a lot of data that exists!\n",
    "- If \"NaN\" possibly means something (i.e. this test was not run), then discarding cells might be a bad idea. \n",
    "- By dropping values in this way, we drop 35 of our 150 \"Not CKD\" observations (23%) but drop 207 of our 250 \"CKD\" observations (83%!!!). This would affect the balance of our classes considerably and may create bias in our models.\n",
    "\n",
    "Losing all of this data is inadvisable, so I will keep all of my data. (You may have made the choice to do a \"complete-case analysis.\" While I personally would not do that here, you can! As a result, your answers below that rely on code may be different.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Thinking critically about how our data were gathered, it's likely that these records were gathered by doctors and nurses. Brainstorm three potential areas (in addition to the missing data we've already discussed) where this data might be inaccurate or imprecise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** _(Answers may vary.)_\n",
    "\n",
    "- Certain variables may be subjective. For example, two different doctors might arrive at two different conclusions for \"appetite.\" What qualifies as \"good\" versus \"poor?\"\n",
    "- For certain variables like \"red blood cells,\" does it make sense to just leave it at \"normal\" versus \"abnormal?\" Are there multiple ways for red blood cells to be \"abnormal?\" This imprecision might make our test less effective than we'd like.\n",
    "- While we assume this isn't the case, it's always possible that the data we have are wrong.\n",
    "    - Maybe lab results were mixed up (i.e. not connected to the correct patient).\n",
    "    - Maybe machines aren't properly calibrated or some contamination occurred so our measurements are incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 6. Suppose that I want to construct a model where no person who has CKD will ever be told that they do not have CKD. What (very simple, no machine learning needed) model can I create that will never tell a person with CKD that they do not have CKD?\n",
    "\n",
    "> Hint: Don't think about `statsmodels` or `scikit-learn` here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** An overly simplistic model would be to tell all people that they have CKD. Thus, no person would ever be told they do not have CKD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. In problem 6, what common classification metric did we optimize for? Did we minimize false positives or negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** In this problem, assuming that CKD is the \"positive\" class, **we minimized false negatives**. This is equivalent to **maximizing sensitivity**.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{Sensitivity} &=& \\frac{\\text{TP}}{\\text{P}} \\\\\n",
    "&=& \\frac{\\text{TP}}{\\text{TP + FN}} \\\\\n",
    "\\Rightarrow 1 &=& \\frac{\\text{TP}}{\\text{TP + FN}} \\\\\n",
    "\\Rightarrow \\text{TP + FN} &=& \\text{TP} \\\\\n",
    "\\Rightarrow \\text{FN} &=& 0 \\\\\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Thinking ethically, what is at least one disadvantage to the model you described in problem 6?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** _(Answers may vary.)_\n",
    "\n",
    "Telling every person they have CKD is unethical because then people will likely pursue expensive treatment options. It also causes lots of anxiety. In the long run, people would stop using your test because of all of the false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Suppose that I want to construct a model where a person who does not have CKD will ever be told that they do have CKD. What (very simple, no machine learning needed) model can I create that will accomplish this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** An overly simplistic model would be to tell no people that they have CKD. Thus, no person would ever be told they do have CKD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. In problem 9, what common classification metric did we optimize for? Did we minimize false positives or negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** In this problem, assuming that CKD is the \"positive\" class, **we minimized false positives**. This is equivalent to **maximizing specificity**.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{Specificity} &=& \\frac{\\text{TN}}{\\text{N}} \\\\\n",
    "&=& \\frac{\\text{TN}}{\\text{TN + FP}} \\\\\n",
    "\\Rightarrow 1 &=& \\frac{\\text{TN}}{\\text{TN + FP}} \\\\\n",
    "\\Rightarrow \\text{TN + FP} &=& \\text{TN} \\\\\n",
    "\\Rightarrow \\text{FP} &=& 0 \\\\\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Thinking ethically, what is at least one disadvantage to the model you described in problem 9?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** _(Answers may vary.)_\n",
    "\n",
    "Telling every person they have CKD is unethical because then people will return home thinking they are healthy when they are not. This would likely result in deaths of patients. Additionally, in the long run, people would stop using your test because of all of the false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Construct a logistic regression model in `sklearn` predicting class from the other variables. You may scale, select/drop, and engineer features as you wish - build a good model! Make sure, however, that you include at least one categorical/dummy feature and at least one quantitative feature.\n",
    "\n",
    "> Hint: Remember to do a train/test split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "     bgr  ...   pcv    wbcc  rbcc  htn   dm  cad  appet   pe  ane class  \n",
       "0  121.0  ...  44.0  7800.0   5.2  yes  yes   no   good   no   no   ckd  \n",
       "1    NaN  ...  38.0  6000.0   NaN   no   no   no   good   no   no   ckd  \n",
       "2  423.0  ...  31.0  7500.0   NaN   no  yes   no   poor   no  yes   ckd  \n",
       "3  117.0  ...  32.0  6700.0   3.9  yes   no   no   poor  yes  yes   ckd  \n",
       "4  106.0  ...  35.0  7300.0   4.6   no   no   no   good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd['y'] = [1 if i == 'ckd' else 0 for i in ckd['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    250\n",
       "0    150\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to create interaction terms in cases where variables may be correlated (I'm not a doctor, but pus cell and pus cell clumps are probably related, right? Same with red and white blood cell counts.)\n",
    "- PC and PCC\n",
    "- WBCC and RBCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd['pc_pcc_interaction'] = [1 if ckd.loc[i, 'pc'] == 'abnormal' and ckd.loc[i, 'pcc'] == 'present' else 0 for i in range(len(ckd['pc']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd['wbcc_rbcc_interaction'] = ckd['wbcc'] * ckd['rbcc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't have great subject-matter expertise for removing anything. Thus, I'm going to include all of my variables (including the interaction terms I just created), then consider dropping some if there's evidence of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "      <th>y</th>\n",
       "      <th>pc_pcc_interaction</th>\n",
       "      <th>wbcc_rbcc_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33580.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "     bgr  ...  htn   dm  cad  appet   pe  ane  class  y pc_pcc_interaction  \\\n",
       "0  121.0  ...  yes  yes   no   good   no   no    ckd  1                  0   \n",
       "1    NaN  ...   no   no   no   good   no   no    ckd  1                  0   \n",
       "2  423.0  ...   no  yes   no   poor   no  yes    ckd  1                  0   \n",
       "3  117.0  ...  yes   no   no   poor  yes  yes    ckd  1                  1   \n",
       "4  106.0  ...   no   no   no   good   no   no    ckd  1                  0   \n",
       "\n",
       "  wbcc_rbcc_interaction  \n",
       "0               40560.0  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3               26130.0  \n",
       "4               33580.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu',\n",
       "       'sc', 'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc', 'htn', 'dm', 'cad',\n",
       "       'appet', 'pe', 'ane', 'class', 'y', 'pc_pcc_interaction',\n",
       "       'wbcc_rbcc_interaction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                      float64\n",
       "bp                       float64\n",
       "sg                       float64\n",
       "al                       float64\n",
       "su                       float64\n",
       "rbc                       object\n",
       "pc                        object\n",
       "pcc                       object\n",
       "ba                        object\n",
       "bgr                      float64\n",
       "bu                       float64\n",
       "sc                       float64\n",
       "sod                      float64\n",
       "pot                      float64\n",
       "hemo                     float64\n",
       "pcv                      float64\n",
       "wbcc                     float64\n",
       "rbcc                     float64\n",
       "htn                       object\n",
       "dm                        object\n",
       "cad                       object\n",
       "appet                     object\n",
       "pe                        object\n",
       "ane                       object\n",
       "class                     object\n",
       "y                          int64\n",
       "pc_pcc_interaction         int64\n",
       "wbcc_rbcc_interaction    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbc_abnormal = pd.get_dummies(ckd['rbc'])['abnormal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_abnormal = pd.get_dummies(ckd['pc'])['abnormal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcc_present = pd.get_dummies(ckd['pcc'])['present']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_present = pd.get_dummies(ckd['ba'])['present']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "htn_yes = pd.get_dummies(ckd['htn'])['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_yes = pd.get_dummies(ckd['dm'])['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_yes = pd.get_dummies(ckd['cad'])['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "appet_poor = pd.get_dummies(ckd['appet'])['poor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_yes = pd.get_dummies(ckd['pe'])['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ane_yes = pd.get_dummies(ckd['ane'])['yes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to set all of my dummy variables up in a dataframe called `qual` (for qualitative) and all my quantitative variables in a dataframe called `quant` (for quantitative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant = ckd[['age', 'bp', 'sg', 'al', 'su', 'bgr',\n",
    "                 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv',\n",
    "                 'wbcc', 'rbcc', 'pc_pcc_interaction',\n",
    "                 'wbcc_rbcc_interaction']]\n",
    "\n",
    "qual = pd.DataFrame([ane_yes, pe_yes, rbc_abnormal, pc_abnormal,\n",
    "                     pcc_present, ba_present, htn_yes, dm_yes,\n",
    "                     cad_yes, appet_poor], index=['ane_yes', 'pe_yes', 'rbc_abnormal',\n",
    "                                                  'pc_abnormal', 'pcc_present',\n",
    "                                                  'ba_present', 'htn_yes', 'dm_yes',\n",
    "                                                  'cad_yes', 'appet_poor']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = quant.merge(right = qual, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>...</th>\n",
       "      <th>ane_yes</th>\n",
       "      <th>pe_yes</th>\n",
       "      <th>rbc_abnormal</th>\n",
       "      <th>pc_abnormal</th>\n",
       "      <th>pcc_present</th>\n",
       "      <th>ba_present</th>\n",
       "      <th>htn_yes</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>cad_yes</th>\n",
       "      <th>appet_poor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>142.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>131.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>138.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>47.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>135.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>62.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>61.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>135.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>42.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>129.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>61.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>141.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>69.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>130.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>69.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>28.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>145.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>72.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>61.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>79.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>146.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>143.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>58.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>147.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>64.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>145.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>71.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>138.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>59.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>137.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>57.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>63.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>146.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>46.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>142.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>15.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>144.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>41.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>140.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>52.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>36.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>57.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>147.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>43.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>50.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>55.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>42.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>141.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>12.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>137.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>58.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>141.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bp     sg   al   su    bgr     bu    sc    sod  pot  ...  \\\n",
       "0    48.0   80.0  1.020  1.0  0.0  121.0   36.0   1.2    NaN  NaN  ...   \n",
       "1     7.0   50.0  1.020  4.0  0.0    NaN   18.0   0.8    NaN  NaN  ...   \n",
       "2    62.0   80.0  1.010  2.0  3.0  423.0   53.0   1.8    NaN  NaN  ...   \n",
       "3    48.0   70.0  1.005  4.0  0.0  117.0   56.0   3.8  111.0  2.5  ...   \n",
       "4    51.0   80.0  1.010  2.0  0.0  106.0   26.0   1.4    NaN  NaN  ...   \n",
       "5    60.0   90.0  1.015  3.0  0.0   74.0   25.0   1.1  142.0  3.2  ...   \n",
       "6    68.0   70.0  1.010  0.0  0.0  100.0   54.0  24.0  104.0  4.0  ...   \n",
       "7    24.0    NaN  1.015  2.0  4.0  410.0   31.0   1.1    NaN  NaN  ...   \n",
       "8    52.0  100.0  1.015  3.0  0.0  138.0   60.0   1.9    NaN  NaN  ...   \n",
       "9    53.0   90.0  1.020  2.0  0.0   70.0  107.0   7.2  114.0  3.7  ...   \n",
       "10   50.0   60.0  1.010  2.0  4.0  490.0   55.0   4.0    NaN  NaN  ...   \n",
       "11   63.0   70.0  1.010  3.0  0.0  380.0   60.0   2.7  131.0  4.2  ...   \n",
       "12   68.0   70.0  1.015  3.0  1.0  208.0   72.0   2.1  138.0  5.8  ...   \n",
       "13   68.0   70.0    NaN  NaN  NaN   98.0   86.0   4.6  135.0  3.4  ...   \n",
       "14   68.0   80.0  1.010  3.0  2.0  157.0   90.0   4.1  130.0  6.4  ...   \n",
       "15   40.0   80.0  1.015  3.0  0.0   76.0  162.0   9.6  141.0  4.9  ...   \n",
       "16   47.0   70.0  1.015  2.0  0.0   99.0   46.0   2.2  138.0  4.1  ...   \n",
       "17   47.0   80.0    NaN  NaN  NaN  114.0   87.0   5.2  139.0  3.7  ...   \n",
       "18   60.0  100.0  1.025  0.0  3.0  263.0   27.0   1.3  135.0  4.3  ...   \n",
       "19   62.0   60.0  1.015  1.0  0.0  100.0   31.0   1.6    NaN  NaN  ...   \n",
       "20   61.0   80.0  1.015  2.0  0.0  173.0  148.0   3.9  135.0  5.2  ...   \n",
       "21   60.0   90.0    NaN  NaN  NaN    NaN  180.0  76.0    4.5  NaN  ...   \n",
       "22   48.0   80.0  1.025  4.0  0.0   95.0  163.0   7.7  136.0  3.8  ...   \n",
       "23   21.0   70.0  1.010  0.0  0.0    NaN    NaN   NaN    NaN  NaN  ...   \n",
       "24   42.0  100.0  1.015  4.0  0.0    NaN   50.0   1.4  129.0  4.0  ...   \n",
       "25   61.0   60.0  1.025  0.0  0.0  108.0   75.0   1.9  141.0  5.2  ...   \n",
       "26   75.0   80.0  1.015  0.0  0.0  156.0   45.0   2.4  140.0  3.4  ...   \n",
       "27   69.0   70.0  1.010  3.0  4.0  264.0   87.0   2.7  130.0  4.0  ...   \n",
       "28   75.0   70.0    NaN  1.0  3.0  123.0   31.0   1.4    NaN  NaN  ...   \n",
       "29   68.0   70.0  1.005  1.0  0.0    NaN   28.0   1.4    NaN  NaN  ...   \n",
       "..    ...    ...    ...  ...  ...    ...    ...   ...    ...  ...  ...   \n",
       "370  69.0   70.0  1.020  0.0  0.0   83.0   42.0   1.2  139.0  3.7  ...   \n",
       "371  28.0   60.0  1.025  0.0  0.0   79.0   50.0   0.5  145.0  5.0  ...   \n",
       "372  72.0   60.0  1.020  0.0  0.0  109.0   26.0   0.9  150.0  4.9  ...   \n",
       "373  61.0   70.0  1.025  0.0  0.0  133.0   38.0   1.0  142.0  3.6  ...   \n",
       "374  79.0   80.0  1.025  0.0  0.0  111.0   44.0   1.2  146.0  3.6  ...   \n",
       "375  70.0   80.0  1.020  0.0  0.0   74.0   41.0   0.5  143.0  4.5  ...   \n",
       "376  58.0   70.0  1.025  0.0  0.0   88.0   16.0   1.1  147.0  3.5  ...   \n",
       "377  64.0   70.0  1.020  0.0  0.0   97.0   27.0   0.7  145.0  4.8  ...   \n",
       "378  71.0   60.0  1.025  0.0  0.0    NaN    NaN   0.9  140.0  4.8  ...   \n",
       "379  62.0   80.0  1.025  0.0  0.0   78.0   45.0   0.6  138.0  3.5  ...   \n",
       "380  59.0   60.0  1.020  0.0  0.0  113.0   23.0   1.1  139.0  3.5  ...   \n",
       "381  71.0   70.0  1.025  0.0  0.0   79.0   47.0   0.5  142.0  4.8  ...   \n",
       "382  48.0   80.0  1.025  0.0  0.0   75.0   22.0   0.8  137.0  5.0  ...   \n",
       "383  80.0   80.0  1.025  0.0  0.0  119.0   46.0   0.7  141.0  4.9  ...   \n",
       "384  57.0   60.0  1.020  0.0  0.0  132.0   18.0   1.1  150.0  4.7  ...   \n",
       "385  63.0   70.0  1.020  0.0  0.0  113.0   25.0   0.6  146.0  4.9  ...   \n",
       "386  46.0   70.0  1.025  0.0  0.0  100.0   47.0   0.5  142.0  3.5  ...   \n",
       "387  15.0   80.0  1.025  0.0  0.0   93.0   17.0   0.9  136.0  3.9  ...   \n",
       "388  51.0   80.0  1.020  0.0  0.0   94.0   15.0   1.2  144.0  3.7  ...   \n",
       "389  41.0   80.0  1.025  0.0  0.0  112.0   48.0   0.7  140.0  5.0  ...   \n",
       "390  52.0   80.0  1.025  0.0  0.0   99.0   25.0   0.8  135.0  3.7  ...   \n",
       "391  36.0   80.0  1.025  0.0  0.0   85.0   16.0   1.1  142.0  4.1  ...   \n",
       "392  57.0   80.0  1.020  0.0  0.0  133.0   48.0   1.2  147.0  4.3  ...   \n",
       "393  43.0   60.0  1.025  0.0  0.0  117.0   45.0   0.7  141.0  4.4  ...   \n",
       "394  50.0   80.0  1.020  0.0  0.0  137.0   46.0   0.8  139.0  5.0  ...   \n",
       "395  55.0   80.0  1.020  0.0  0.0  140.0   49.0   0.5  150.0  4.9  ...   \n",
       "396  42.0   70.0  1.025  0.0  0.0   75.0   31.0   1.2  141.0  3.5  ...   \n",
       "397  12.0   80.0  1.020  0.0  0.0  100.0   26.0   0.6  137.0  4.4  ...   \n",
       "398  17.0   60.0  1.025  0.0  0.0  114.0   50.0   1.0  135.0  4.9  ...   \n",
       "399  58.0   80.0  1.025  0.0  0.0  131.0   18.0   1.1  141.0  3.5  ...   \n",
       "\n",
       "     ane_yes  pe_yes  rbc_abnormal  pc_abnormal  pcc_present  ba_present  \\\n",
       "0          0       0             0            0            0           0   \n",
       "1          0       0             0            0            0           0   \n",
       "2          1       0             0            0            0           0   \n",
       "3          1       1             0            1            1           0   \n",
       "4          0       0             0            0            0           0   \n",
       "5          0       1             0            0            0           0   \n",
       "6          0       0             0            0            0           0   \n",
       "7          0       1             0            1            0           0   \n",
       "8          1       0             0            1            1           0   \n",
       "9          1       0             1            1            1           0   \n",
       "10         1       0             0            1            1           0   \n",
       "11         0       1             1            1            1           0   \n",
       "12         0       1             0            0            1           0   \n",
       "13         0       1             0            0            0           0   \n",
       "14         0       1             0            1            1           1   \n",
       "15         1       0             0            0            0           0   \n",
       "16         0       0             0            0            0           0   \n",
       "17         0       0             0            0            0           0   \n",
       "18         0       0             0            0            0           0   \n",
       "19         0       0             0            1            1           0   \n",
       "20         1       1             1            1            0           0   \n",
       "21         0       0             0            0            0           0   \n",
       "22         1       0             0            1            0           0   \n",
       "23         1       0             0            0            0           0   \n",
       "24         0       0             0            1            0           1   \n",
       "25         1       0             0            0            0           0   \n",
       "26         0       0             0            0            0           0   \n",
       "27         0       1             0            1            0           0   \n",
       "28         0       0             0            0            0           0   \n",
       "29         0       0             1            1            1           0   \n",
       "..       ...     ...           ...          ...          ...         ...   \n",
       "370        0       0             0            0            0           0   \n",
       "371        0       0             0            0            0           0   \n",
       "372        0       0             0            0            0           0   \n",
       "373        0       0             0            0            0           0   \n",
       "374        0       0             0            0            0           0   \n",
       "375        0       0             0            0            0           0   \n",
       "376        0       0             0            0            0           0   \n",
       "377        0       0             0            0            0           0   \n",
       "378        0       0             0            0            0           0   \n",
       "379        0       0             0            0            0           0   \n",
       "380        0       0             0            0            0           0   \n",
       "381        0       0             0            0            0           0   \n",
       "382        0       0             0            0            0           0   \n",
       "383        0       0             0            0            0           0   \n",
       "384        0       0             0            0            0           0   \n",
       "385        0       0             0            0            0           0   \n",
       "386        0       0             0            0            0           0   \n",
       "387        0       0             0            0            0           0   \n",
       "388        0       0             0            0            0           0   \n",
       "389        0       0             0            0            0           0   \n",
       "390        0       0             0            0            0           0   \n",
       "391        0       0             0            0            0           0   \n",
       "392        0       0             0            0            0           0   \n",
       "393        0       0             0            0            0           0   \n",
       "394        0       0             0            0            0           0   \n",
       "395        0       0             0            0            0           0   \n",
       "396        0       0             0            0            0           0   \n",
       "397        0       0             0            0            0           0   \n",
       "398        0       0             0            0            0           0   \n",
       "399        0       0             0            0            0           0   \n",
       "\n",
       "     htn_yes  dm_yes  cad_yes  appet_poor  \n",
       "0          1       1        0           0  \n",
       "1          0       0        0           0  \n",
       "2          0       1        0           1  \n",
       "3          1       0        0           1  \n",
       "4          0       0        0           0  \n",
       "5          1       1        0           0  \n",
       "6          0       0        0           0  \n",
       "7          0       1        0           0  \n",
       "8          1       1        0           0  \n",
       "9          1       1        0           1  \n",
       "10         1       1        0           0  \n",
       "11         1       1        0           1  \n",
       "12         1       1        1           1  \n",
       "13         1       1        1           1  \n",
       "14         1       1        1           1  \n",
       "15         1       0        0           0  \n",
       "16         0       0        0           0  \n",
       "17         1       0        0           1  \n",
       "18         1       1        1           0  \n",
       "19         1       0        1           0  \n",
       "20         1       1        1           1  \n",
       "21         1       1        1           0  \n",
       "22         1       0        0           0  \n",
       "23         0       0        0           1  \n",
       "24         1       0        0           1  \n",
       "25         1       1        0           0  \n",
       "26         1       1        0           1  \n",
       "27         1       1        1           0  \n",
       "28         0       1        0           0  \n",
       "29         0       0        1           0  \n",
       "..       ...     ...      ...         ...  \n",
       "370        0       0        0           0  \n",
       "371        0       0        0           0  \n",
       "372        0       0        0           0  \n",
       "373        0       0        0           0  \n",
       "374        0       0        0           0  \n",
       "375        0       0        0           0  \n",
       "376        0       0        0           0  \n",
       "377        0       0        0           0  \n",
       "378        0       0        0           0  \n",
       "379        0       0        0           0  \n",
       "380        0       0        0           0  \n",
       "381        0       0        0           0  \n",
       "382        0       0        0           0  \n",
       "383        0       0        0           0  \n",
       "384        0       0        0           0  \n",
       "385        0       0        0           0  \n",
       "386        0       0        0           0  \n",
       "387        0       0        0           0  \n",
       "388        0       0        0           0  \n",
       "389        0       0        0           0  \n",
       "390        0       0        0           0  \n",
       "391        0       0        0           0  \n",
       "392        0       0        0           0  \n",
       "393        0       0        0           0  \n",
       "394        0       0        0           0  \n",
       "395        0       0        0           0  \n",
       "396        0       0        0           0  \n",
       "397        0       0        0           0  \n",
       "398        0       0        0           0  \n",
       "399        0       0        0           0  \n",
       "\n",
       "[400 rows x 26 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran into a lot of data munging issues with `X`. The NAs in the dataframe were throwing it off. I decided to take a **very** rudimentary approach by filling in the mean.\n",
    "\n",
    "### NOTE: FILLING IN THE MEAN IS USUALLY CATASTROPHIC FOR YOUR ANALYSIS. We will learn proper methods of imputation later in the class. This quick fix leads to lots negative side effects, especially if you're attempting to conduct inference. I am using this quick fix so as to not distract from the point of the lab, but using mean imputation is inadvisable in most circumstances. *Proceed with caution.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.fillna(X.mean()),\n",
    "                                                    ckd['y'],\n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "              'class_weight': [None, 'balanced'],\n",
    "              'penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "gs_results = GridSearchCV(estimator = LogisticRegression(random_state = 42), # Specify the model we want to GridSearch.\n",
    "                          param_grid = parameters,                           # Specify the grid of parameters we want to search.\n",
    "                          scoring = 'recall',                                # Specify recall as the metric to optimize \n",
    "                          cv = 5).fit(X_train, y_train)                      # Set 5-fold cross-validation, then fit. (Default is 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of this GridSearch, our best model is that which:\n",
    "- Has an inverse regularization strength of $C = 10$.\n",
    "- Balances our `class_weight` (weighting our `y` variables so each class makes up 50%).\n",
    "- Has the `L2` penalty (i.e. Ridge regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C = 10.0,\n",
    "                           class_weight = 'balanced',\n",
    "                           penalty = 'l2',\n",
    "                           random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=42,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X = X_train,\n",
    "          y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857142857142858"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Evaluate the model.\n",
    "\n",
    "### 13. Based on your logistic regression model constructed in problem 12, interpret the coefficient of one of your quantitative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0099651781598211, 'age'),\n",
       " (1.1233807656230583, 'bp'),\n",
       " (1.1838904564998989, 'sg'),\n",
       " (29.583514166538958, 'al'),\n",
       " (2.839273392413368, 'su'),\n",
       " (1.0370133004786155, 'bgr'),\n",
       " (0.9281193722479492, 'bu'),\n",
       " (11.648855346652514, 'sc'),\n",
       " (1.0679922666228185, 'sod'),\n",
       " (1.3323759297645434, 'pot'),\n",
       " (0.1883938297975334, 'hemo'),\n",
       " (1.0064450238107634, 'pcv'),\n",
       " (0.9996226639003896, 'wbcc'),\n",
       " (0.3577306956563031, 'rbcc'),\n",
       " (1.0664966787225318, 'pc_pcc_interaction'),\n",
       " (1.0000705407431232, 'wbcc_rbcc_interaction'),\n",
       " (1.6210641073013128, 'ane_yes'),\n",
       " (5.403291530347749, 'pe_yes'),\n",
       " (2.0630211326062167, 'rbc_abnormal'),\n",
       " (1.9356863909775321, 'pc_abnormal'),\n",
       " (1.083027005854006, 'pcc_present'),\n",
       " (1.0239451328610731, 'ba_present'),\n",
       " (4.144480154792974, 'htn_yes'),\n",
       " (4.032148928503803, 'dm_yes'),\n",
       " (1.0593278095037473, 'cad_yes'),\n",
       " (4.568790816163472, 'appet_poor')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(np.exp(logit.coef_[0]),X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** As serum creatinine (`sc`) increases by one unit (mgs/dl), an individual is 11.85 times as likely to have CKD, all else held equal.\n",
    "- Note that I exponentiated the coefficients!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Based on your logistic regression model constructed in problem 12, interpret the coefficient of one of your categorical/dummy features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0099651781598211, 'age'),\n",
       " (1.1233807656230583, 'bp'),\n",
       " (1.1838904564998989, 'sg'),\n",
       " (29.583514166538958, 'al'),\n",
       " (2.839273392413368, 'su'),\n",
       " (1.0370133004786155, 'bgr'),\n",
       " (0.9281193722479492, 'bu'),\n",
       " (11.648855346652514, 'sc'),\n",
       " (1.0679922666228185, 'sod'),\n",
       " (1.3323759297645434, 'pot'),\n",
       " (0.1883938297975334, 'hemo'),\n",
       " (1.0064450238107634, 'pcv'),\n",
       " (0.9996226639003896, 'wbcc'),\n",
       " (0.3577306956563031, 'rbcc'),\n",
       " (1.0664966787225318, 'pc_pcc_interaction'),\n",
       " (1.0000705407431232, 'wbcc_rbcc_interaction'),\n",
       " (1.6210641073013128, 'ane_yes'),\n",
       " (5.403291530347749, 'pe_yes'),\n",
       " (2.0630211326062167, 'rbc_abnormal'),\n",
       " (1.9356863909775321, 'pc_abnormal'),\n",
       " (1.083027005854006, 'pcc_present'),\n",
       " (1.0239451328610731, 'ba_present'),\n",
       " (4.144480154792974, 'htn_yes'),\n",
       " (4.032148928503803, 'dm_yes'),\n",
       " (1.0593278095037473, 'cad_yes'),\n",
       " (4.568790816163472, 'appet_poor')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(np.exp(logit.coef_[0]),X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** If someone's appetite is poor `appet_poor`, they are 4.64 times as likely to have CKD, all else held equal.\n",
    "- Note that I exponentiated the coefficients!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Despite being a relatively simple model, logistic regression is very widely used in the real world. Why do you think that's the case? Name at least two advantages to using logistic regression as a modeling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** _(Answers may vary.)_\n",
    "\n",
    "- Logistic regression allows for interpretable coefficients so that we can understand how `X` affects `y`, as we saw above.\n",
    "- Logistic regression usually does not suffer from high variance due to the large number of simplifying assumptions placed on the model. (i.e. features are \"linear in the logit,\" errors are independent and follow a Bernoulli distribution, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Does it make sense to generate a confusion matrix on our training data or our test data? Why? Generate it on the proper data.\n",
    "\n",
    "> Hint: Once you've generated your predicted $y$ values and you have your observed $y$ values, then it will be easy to [generate a confusion matrix using sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** It makes more sense to generate a confusion matrix on our **test data**, as that provides a proper evaluation of our methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  1],\n",
       "       [ 2, 74]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 43\n",
      "\n",
      "False Positives: 1\n",
      "\n",
      "False Negatives: 2\n",
      "\n",
      "True Positives: 74\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negatives: \" + str(tn))\n",
    "print()\n",
    "print(\"False Positives: \" + str(fp))\n",
    "print()\n",
    "print(\"False Negatives: \" + str(fn))\n",
    "print()\n",
    "print(\"True Positives: \" + str(tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. In this hospital case, we want to predict CKD. Do we want to optimize for sensitivity, specificity, or something else? Why? (If you don't think there's one clear answer, that's okay! There rarely is. Be sure to defend your conclusion!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** _(Answers may vary.)_\n",
    "\n",
    "We probably want to find some combination of sensitivity and specificity. \n",
    "- Focusing only on sensitivity means we minimize false negatives. This means there will be few people we incorrectly predict to be healthy, but more people we incorrectly predict to be sick.\n",
    "- Focusing only on specificity means we minimize false positives. This means there will be few people we incorrectly predict to be sick, but more people we incorrectly predict to be healthy.\n",
    "\n",
    "I don't think sensitivity and specificity are equally important, though. I think sensitivity is more important (I'd rather tell people they have CKD and be wrong than tell people they're healthy and have them get sick.).\n",
    "\n",
    "Four potential options I would consider in this case:\n",
    "- Just go with optimizing sensitivity, as it's better than optimizing specificity.\n",
    "- I might try to optimize `f1-score`, a combination of sensitivity and specificity.\n",
    "- I might try to optimize a custom metric that weighs sensitivity somewhat more importantly than specificity.\n",
    "- I might look at my ROC curve and try to find a place where sensitivity is very high and 1 - specificity is pretty low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Write a function that will create an ROC curve for you, then plot the ROC curve.\n",
    "\n",
    "Here's a strategy you might consider:\n",
    "1. In order to even begin, you'll need some fit model. Use your logistic regression model from problem 12.\n",
    "2. We want to look at all values of your \"threshold\" - that is, anything where .predict() gives you above your threshold falls in the \"positive class,\" and anything that is below your threshold falls in the \"negative class.\" Start the threshold at 0.\n",
    "3. At this value of your threshold, calculate the sensitivity and specificity. Store these values.\n",
    "4. Increment your threshold by some \"step.\" Maybe set your step to be 0.01, or even smaller.\n",
    "5. At this value of your threshold, calculate the sensitivity and specificity. Store these values.\n",
    "6. Repeat steps 3 and 4 until you get to the threshold of 1.\n",
    "7. Plot the values of sensitivity and 1 - specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc(probas, true, step=0.01):\n",
    "    \"\"\"\n",
    "    probas should be a numpy array of predict_probas\n",
    "    true is a pandas series of true labels\n",
    "    step is the step size for checking thresholds\n",
    "    \"\"\"\n",
    "    \n",
    "    probas = probas[:,1]  # The output of predict_proba() is an array of the probabilities for every class, but we only want the probabilities for class 1\n",
    "    true = true.values    # We need to convert the class labels from a Pandas Series to a numpy array. We do this using the .values attribute\n",
    "    assert(len(probas) == len(true)) # We're making sure that our probabilities vector is the same length as our true class labesl vector\n",
    "    \n",
    "    TPRs = [] # Setting up empty list of True Positive Rate\n",
    "    FPRs = [] # Setting up empty list of False Positive Rate\n",
    "    \n",
    "    for i in np.arange(0.0,1.0,step): # np.arange allows us to use step sizes that are decimals\n",
    "        preds_class = probas > i # Numpy arrays have a feature called 'broadcasting.' Check the documentation: https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html to see what this does.\n",
    "        TP = 0 \n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        for index in range(len(preds_class)): # We're comparing each prediction with each true value here\n",
    "\n",
    "            if preds_class[index] == 1 and true[index] == 1:\n",
    "                TP += 1\n",
    "            elif preds_class[index] == 1 and true[index] == 0:\n",
    "                FP += 1\n",
    "            elif preds_class[index] == 0 and true[index] == 0:\n",
    "                TN += 1 \n",
    "            elif preds_class[index] == 0 and true[index] == 1:\n",
    "                FN += 1\n",
    "                \n",
    "        TPR = TP/(TP + FN) # Calculating TPR and FPR and appending to our lists\n",
    "        FPR = FP/(FP + TN)\n",
    "        \n",
    "        TPRs.append(TPR)\n",
    "        FPRs.append(FPR)\n",
    "         \n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.plot(FPRs, TPRs, color=\"orange\")\n",
    "    plt.plot([0,1],[0,1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "    plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "probabilities = logit.predict_proba(X_test)\n",
    "\n",
    "roc(probas = probabilities, # pass in series of probabilities \n",
    "    true = y_test,          # pass in series of true values\n",
    "    step=0.001);            # pass in step size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Suppose you're speaking with the biostatistics lead at Mayo Clinic, who asks you \"Why are unbalanced classes generally a problem? Are they a problem in this particular CKD analysis?\" How would you respond?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** _(Answers may vary.)_\n",
    "- Unbalanced classes are usually a problem because our model has a tough time learning about the minority class. There's simply not enough data to learn the \"pattern\" or \"behavior\" of the minority class.\n",
    "- They probably aren't a problem in this CKD analysis. A 40/60 split isn't substantially unbalanced. However, in gridsearching over whether or not to balance our classes, GridSearchCV found that our model performs better when we balance our `y` classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Suppose you're speaking with a doctor at Mayo Clinic who, despite being very smart, doesn't know much about data science or statistics. How would you explain why unbalanced classes are generally a problem to this doctor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** _(Answers may vary.)_\n",
    "\n",
    "Let's say you treat a patient who comes in with a broken arm. These happen pretty frequently, so you have a good idea of how to fix it, what potential complications are, etc. On the other hand, let's say you treat a patient who presents with odd symptoms that you've never seen before. You check books and do research, but it's very hard to understand this disease becauses you just don't have enough information to identify causes or recommend treatments.\n",
    "\n",
    "That is the problem of unbalanced classes. When we build a model where we have lots of broken arms but very few \"rare diseases,\" it's hard for our model to learn about those rare diseases because we see them so infrequently that we don't have enough information.\n",
    "\n",
    "> This type of skill - explaining things to a non-technical audience - is a very important skill to have. Practice honing this skill as much as you can! Whether you're in an interview with a non-technical peer or you have a phone screen with [Linda from human resources](https://www.youtube.com/watch?v=31rjM7_wKoE), you want to be able to explain technical topics to non-technical people. (Like your capstone!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Let's create very unbalanced classes just for the sake of this example! Generate very unbalanced classes by [bootstrapping](http://stattrek.com/statistics/dictionary.aspx?definition=sampling_with_replacement) (a.k.a. random sampling with replacement) the majority class.\n",
    "\n",
    "1. The majority class are those individuals with CKD.\n",
    "2. Generate a random sample of size 200,000 of individuals who have CKD with replacement. (Consider setting a random seed for this part!)\n",
    "3. Create a new dataframe with the original data plus this random sample of data.\n",
    "4. Now we should have a dataset with around 200,000 observations, of which only about 0.00075% are non-CKD individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You may have fewer than 200,000 observations if you chose to drop missing values above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd_sample = ckd[ckd['class'] == 'ckd'].sample(200_000,            # sample n = 200,000\n",
    "                                               replace = True,     # sample with replacement\n",
    "                                               random_state = 42)  # set random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd_2 = pd.concat([ckd, ckd_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200400, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "      <th>y</th>\n",
       "      <th>pc_pcc_interaction</th>\n",
       "      <th>wbcc_rbcc_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33580.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "     bgr  ...  htn   dm  cad  appet   pe  ane  class  y pc_pcc_interaction  \\\n",
       "0  121.0  ...  yes  yes   no   good   no   no    ckd  1                  0   \n",
       "1    NaN  ...   no   no   no   good   no   no    ckd  1                  0   \n",
       "2  423.0  ...   no  yes   no   poor   no  yes    ckd  1                  0   \n",
       "3  117.0  ...  yes   no   no   poor  yes  yes    ckd  1                  1   \n",
       "4  106.0  ...   no   no   no   good   no   no    ckd  1                  0   \n",
       "\n",
       "  wbcc_rbcc_interaction  \n",
       "0               40560.0  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3               26130.0  \n",
       "4               33580.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ckd       99.92515\n",
       "notckd     0.07485\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * ckd_2['class'].value_counts() / len(ckd_2['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Build a logistic regression model on the unbalanced class data and evaluate its performance using whatever method(s) you see fit. How would you describe the impact of unbalanced classes on logistic regression as a classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, I'm not going to artificially balance the classes. I **want** to see the impact of unbalanced classes on my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "quant = ckd_2[['age', 'bp', 'sg', 'al', 'su', 'bgr',\n",
    "                 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv',\n",
    "                 'wbcc', 'rbcc', 'pc_pcc_interaction',\n",
    "                 'wbcc_rbcc_interaction', 'y']]\n",
    "\n",
    "quant.loc[:,'rbc_abnormal_2'] = pd.get_dummies(ckd_2['rbc'])['abnormal']\n",
    "quant.loc[:,'pc_abnormal_2'] = pd.get_dummies(ckd_2['pc'])['abnormal']\n",
    "quant.loc[:,'pcc_present_2'] = pd.get_dummies(ckd_2['pcc'])['present']\n",
    "quant.loc[:,'ba_present_2'] = pd.get_dummies(ckd_2['ba'])['present']\n",
    "quant.loc[:,'htn_yes_2'] = pd.get_dummies(ckd_2['htn'])['yes']\n",
    "quant.loc[:,'dm_yes_2'] = pd.get_dummies(ckd_2['dm'])['yes']\n",
    "quant.loc[:,'cad_yes_2'] = pd.get_dummies(ckd_2['cad'])['yes']\n",
    "quant.loc[:,'appet_poor_2'] = pd.get_dummies(ckd_2['appet'])['poor']\n",
    "quant.loc[:,'pe_yes_2'] = pd.get_dummies(ckd_2['pe'])['yes']\n",
    "quant.loc[:,'ane_yes_2'] = pd.get_dummies(ckd_2['ane'])['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>...</th>\n",
       "      <th>rbc_abnormal_2</th>\n",
       "      <th>pc_abnormal_2</th>\n",
       "      <th>pcc_present_2</th>\n",
       "      <th>ba_present_2</th>\n",
       "      <th>htn_yes_2</th>\n",
       "      <th>dm_yes_2</th>\n",
       "      <th>cad_yes_2</th>\n",
       "      <th>appet_poor_2</th>\n",
       "      <th>pe_yes_2</th>\n",
       "      <th>ane_yes_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su    bgr    bu   sc    sod  pot  ...  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0  121.0  36.0  1.2    NaN  NaN  ...   \n",
       "1   7.0  50.0  1.020  4.0  0.0    NaN  18.0  0.8    NaN  NaN  ...   \n",
       "2  62.0  80.0  1.010  2.0  3.0  423.0  53.0  1.8    NaN  NaN  ...   \n",
       "3  48.0  70.0  1.005  4.0  0.0  117.0  56.0  3.8  111.0  2.5  ...   \n",
       "4  51.0  80.0  1.010  2.0  0.0  106.0  26.0  1.4    NaN  NaN  ...   \n",
       "\n",
       "   rbc_abnormal_2  pc_abnormal_2  pcc_present_2  ba_present_2  htn_yes_2  \\\n",
       "0               0              0              0             0          1   \n",
       "1               0              0              0             0          0   \n",
       "2               0              0              0             0          0   \n",
       "3               0              1              1             0          1   \n",
       "4               0              0              0             0          0   \n",
       "\n",
       "   dm_yes_2  cad_yes_2  appet_poor_2  pe_yes_2  ane_yes_2  \n",
       "0         1          0             0         0          0  \n",
       "1         0          0             0         0          0  \n",
       "2         1          0             1         0          1  \n",
       "3         0          0             1         1          1  \n",
       "4         0          0             0         0          0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200400, 27)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo',\n",
       "       'pcv', 'wbcc', 'rbcc', 'pc_pcc_interaction', 'wbcc_rbcc_interaction',\n",
       "       'y', 'rbc_abnormal_2', 'pc_abnormal_2', 'pcc_present_2', 'ba_present_2',\n",
       "       'htn_yes_2', 'dm_yes_2', 'cad_yes_2', 'appet_poor_2', 'pe_yes_2',\n",
       "       'ane_yes_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(quant.fillna(quant.mean()).drop(['y'],\n",
    "                                                                                    axis = 1),\n",
    "                                                    quant['y'],\n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_2 = LogisticRegression(C = 10,\n",
    "                             random_state = 42,\n",
    "                             penalty = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67        56\n",
      "           1       1.00      1.00      1.00     60064\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     60120\n",
      "   macro avg       1.00      0.75      0.83     60120\n",
      "weighted avg       1.00      1.00      1.00     60120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,\n",
    "                            logit_2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** _(Answers may vary.)_\n",
    "\n",
    "I'm comparing my models based on **sensitivity**. Sensitivity is also known as **recall** or the **true positive rate**.\n",
    "\n",
    "- In this case, my sensitivity score (true positives / all positives) is 100%.\n",
    "- Earlier, the logistic regression model fit on my more balanced data had a sensitivity of 74 / 76, or about 93%.\n",
    "\n",
    "In this case, it seems as though unbalanced classes actually makes our model perform **better**. This will usually not happen. However, let's think through unbalanced classes.\n",
    "\n",
    "- The problem with unbalanced classes is that our algorithms have trouble learning the patterns in the minority class. There usually isn't enough data to learn what causes the minority class.\n",
    "- In the case of predicting CKD, it's likely that a handful of factors will predict CKD. It's unlikely that 10 different variables contribute to detecting CKD. Maybe we only need a small amount of data ($n = 150$) to identify CKD. We could test this theory by undersampling the CKD group to be like $n = 20$ or $n = 30$. \n",
    "- On the other hand, the majority class is probably quite diverse. Different people will have lots of different levels of all of these variables. Augmenting the majority class won't necessarily add noise to our model.\n",
    "- Thus, if we have enough data in our minority class to detect CKD, then we our model won't necessarily be biased!\n",
    "\n",
    "Note that we also wouldn't likely just want to compare models on one metric, like sensitivity. Using multiple metrics to compare these models may be warranted - and in a case where we're dealing with humans and disease, it's very important to consider any of the downsides of optimizing only one metric!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "\n",
    "- At this step, you would generally answer the problem! In this situation, you would likely present your model to doctors or administrators at the hospital and show how your model results in reduced false positives/false negatives. Next steps would be to find a way to roll this model and its conclusions out across the hospital so that the outcomes of patients with CKD (and without CKD!) can be improved!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
